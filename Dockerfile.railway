# syntax=docker/dockerfile:1
# ============================================================
# Slim Railway Deployment Dockerfile for MiraWebUI
# Strips out all local ML models (torch, whisper, embeddings)
# since this deployment uses external APIs only (Groq, ElevenLabs, etc.)
# ============================================================

ARG BUILD_HASH=dev-build

######## Stage 1: Build Frontend ########
FROM node:22-alpine3.20 AS build
ARG BUILD_HASH

# Increase Node.js heap for large builds
ENV NODE_OPTIONS="--max-old-space-size=4096"

WORKDIR /app

RUN apk add --no-cache git

COPY package.json package-lock.json ./
RUN npm ci --force

COPY . .
ENV APP_BUILD_HASH=${BUILD_HASH}
RUN npm run build

######## Stage 2: Python Backend (Slim) ########
FROM python:3.11.14-slim-bookworm AS base

# Python settings
ENV PYTHONUNBUFFERED=1

## App config defaults ##
ENV ENV=prod \
    PORT=8080 \
    # Disable all local ML model downloads
    USE_SLIM_DOCKER=true \
    USE_OLLAMA_DOCKER=false \
    USE_CUDA_DOCKER=false

## API config defaults ##
ENV OLLAMA_BASE_URL="" \
    OPENAI_API_BASE_URL="" \
    OPENAI_API_KEY="" \
    WEBUI_SECRET_KEY="" \
    SCARF_NO_ANALYTICS=true \
    DO_NOT_TRACK=true \
    ANONYMIZED_TELEMETRY=false

## Disable Ollama, enable Groq via OpenAI-compatible API ##
## OPENAI_API_KEY + OPENAI_API_BASE_URL must be set in Railway Variables ##
ENV ENABLE_OLLAMA_API=false \
    ENABLE_OPENAI_API=true \
    TASK_MODEL_EXTERNAL="llama-3.2-1b-preview"

## Pipecat voice AI backend ##
## PIPECAT_API_URL must be set as a Railway environment variable ##
ENV PIPECAT_ENABLED=true \
    PIPECAT_CONNECTION_MODE=websocket \
    PIPECAT_API_URL=""

## Session & auth ##
## 30-day sessions so users aren't forced to re-login constantly ##
ENV JWT_EXPIRES_IN="30d"

## Disable local model downloads at startup ##
ENV RAG_EMBEDDING_MODEL="" \
    RAG_RERANKING_MODEL="" \
    WHISPER_MODEL="" \
    TIKTOKEN_ENCODING_NAME="cl100k_base" \
    TIKTOKEN_CACHE_DIR="/app/backend/data/cache/tiktoken" \
    HF_HOME="/app/backend/data/cache/embedding/models" \
    SENTENCE_TRANSFORMERS_HOME="/app/backend/data/cache/embedding/models"

WORKDIR /app/backend

# Install minimal system dependencies only
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    git curl jq netcat-openbsd \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies (slim set â€” no torch, no whisper, no heavy ML)
COPY ./backend/requirements-railway.txt ./requirements.txt

RUN pip3 install --no-cache-dir uv && \
    uv pip install --system -r requirements.txt --no-cache-dir && \
    mkdir -p /app/backend/data && \
    rm -rf /var/lib/apt/lists/*

# Copy built frontend from Stage 1
COPY --from=build /app/build /app/build
COPY --from=build /app/CHANGELOG.md /app/CHANGELOG.md
COPY --from=build /app/package.json /app/package.json

# Copy backend source
COPY ./backend .

EXPOSE 8080

HEALTHCHECK CMD curl --silent --fail http://localhost:${PORT:-8080}/health | jq -ne 'input.status == true' || exit 1

ARG BUILD_HASH
ENV WEBUI_BUILD_VERSION=${BUILD_HASH}
ENV DOCKER=true

CMD ["bash", "start.sh"]
